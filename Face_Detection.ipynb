{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZcJN-5WY58i"
      },
      "source": [
        "# Face Detection Model Comparison\n",
        "## So sánh các model Object Detection cho dataset 300 folders khuôn mặt sinh viên\n",
        "\n",
        "### Models được so sánh:\n",
        "1. Vanilla CNN\n",
        "2. AdaBoost + Haar Features  \n",
        "3. ResNet50-based Detection\n",
        "4. Modern YOLO-style approach\n",
        "\n",
        "### Metrics đánh giá:\n",
        "- Accuracy\n",
        "- Precision/Recall\n",
        "- Training time\n",
        "- Inference time\n",
        "- Model size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zelo1fJxY58n",
        "outputId": "c699f9d5-0e19-4d68-952b-5d3d7a7fe434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for Google Colab\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q seaborn\n",
        "!pip install -q pandas\n",
        "\n",
        "print(\"[OK] All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlosJa1_Y58p",
        "outputId": "95b5afe6-0651-4d8a-f11f-35e92939b6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            " Dataset found at: /content/drive/MyDrive/aligned_faces\n",
            "  Number of student folders found: 294\n",
            " Results will be saved to: /content/drive/MyDrive/face_detection_results\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import time\n",
        "import pickle\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup paths with error handling\n",
        "DATASET_DIR_DRIVE = \"/content/drive/MyDrive/aligned_faces\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/face_detection_results\"\n",
        "\n",
        "# Check if dataset directory exists\n",
        "if not os.path.exists(DATASET_DIR_DRIVE):\n",
        "    print(f\" Warning: Dataset directory not found at {DATASET_DIR_DRIVE}\")\n",
        "    print(\"Please ensure your dataset is uploaded to Google Drive at the correct path.\")\n",
        "    print(\"Alternative paths to check:\")\n",
        "    print(\"  - /content/drive/My Drive/aligned_faces\")\n",
        "    print(\"  - /content/drive/MyDrive/your_dataset_folder\")\n",
        "    # Try to list available directories in Google Drive\n",
        "    try:\n",
        "        drive_path = \"/content/drive/MyDrive/\"\n",
        "        if os.path.exists(drive_path):\n",
        "            print(f\"\\nAvailable folders in {drive_path}:\")\n",
        "            folders = [f for f in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, f))]\n",
        "            for folder in folders[:10]:  # Show first 10 folders\n",
        "                print(f\"  - {folder}\")\n",
        "    except:\n",
        "        pass\n",
        "else:\n",
        "    print(f\"[OK] Dataset found at: {DATASET_DIR_DRIVE}\")\n",
        "    # Count number of folders\n",
        "    try:\n",
        "        num_folders = len([f for f in os.listdir(DATASET_DIR_DRIVE) if os.path.isdir(os.path.join(DATASET_DIR_DRIVE, f))])\n",
        "        print(f\"  Number of student folders found: {num_folders}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"[OK] Results will be saved to: {RESULTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZcAxv5cY58r",
        "outputId": "1bfdb588-7963-4bfd-d2ba-5b0f711e49a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "SYSTEM INFORMATION\n",
            "==================================================\n",
            " GPU Available: NVIDIA L4\n",
            "  - GPU Memory: 22.16 GB\n",
            "  - CUDA Version: 12.6\n",
            "\n",
            " RAM: 52.96 GB (Available: 50.60 GB)\n",
            "\n",
            " PyTorch Version: 2.8.0+cu126\n",
            " OpenCV Version: 4.12.0\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Check system info and GPU availability\n",
        "print(\"=\"*50)\n",
        "print(\"SYSTEM INFORMATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"[GPU] Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  - GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    print(f\"  - CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"[WARNING] No GPU detected. Training will be slower on CPU.\")\n",
        "    print(\"  To enable GPU in Colab: Runtime -> Change runtime type -> GPU\")\n",
        "\n",
        "# Check RAM\n",
        "try:\n",
        "    import psutil\n",
        "    ram = psutil.virtual_memory()\n",
        "    print(f\"\\n[RAM] {ram.total / 1024**3:.2f} GB (Available: {ram.available / 1024**3:.2f} GB)\")\n",
        "except:\n",
        "    print(\"\\n[INFO] RAM info not available\")\n",
        "\n",
        "# PyTorch version\n",
        "print(f\"\\n[INFO] PyTorch Version: {torch.__version__}\")\n",
        "print(f\"[INFO] OpenCV Version: {cv2.__version__}\")\n",
        "\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbgsP2NtY58s"
      },
      "source": [
        "## 1. Dataset Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAkudArfY58t",
        "outputId": "0f609256-494e-4446-a349-f8002266000d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating datasets...\n",
            "Found 294 student folders\n",
            "Total samples: 5880\n",
            "Number of classes: 294\n",
            " Train: 4116, Val: 882, Test: 882\n",
            " Number of classes: 294\n"
          ]
        }
      ],
      "source": [
        "class FaceDataset(Dataset):\n",
        "    \"\"\"Dataset for face recognition with 300 student folders\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None, max_samples_per_class=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = []\n",
        "        self.class_to_idx = {}\n",
        "        self.samples = []\n",
        "\n",
        "        # Check if root directory exists\n",
        "        if not os.path.exists(root_dir):\n",
        "            raise ValueError(f\"Dataset directory not found: {root_dir}\")\n",
        "\n",
        "        # Get all student folders\n",
        "        try:\n",
        "            folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
        "            folders.sort()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading dataset directory: {e}\")\n",
        "            folders = []\n",
        "\n",
        "        print(f\"Found {len(folders)} student folders\")\n",
        "\n",
        "        for idx, folder in enumerate(folders):\n",
        "            if len(self.classes) >= 300:  # Limit to 300 classes\n",
        "                break\n",
        "\n",
        "            folder_path = os.path.join(root_dir, folder)\n",
        "            \n",
        "            # Try to read folder with error handling for connection issues\n",
        "            try:\n",
        "                images = [f for f in os.listdir(folder_path)\n",
        "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "                \n",
        "                # Skip empty folders\n",
        "                if len(images) == 0:\n",
        "                    print(f\"Skipping empty folder: {folder}\")\n",
        "                    continue\n",
        "                \n",
        "                # Add this class\n",
        "                self.classes.append(folder)\n",
        "                current_idx = len(self.classes) - 1  # Use actual class index\n",
        "                self.class_to_idx[folder] = current_idx\n",
        "\n",
        "                if max_samples_per_class:\n",
        "                    images = images[:max_samples_per_class]\n",
        "\n",
        "                for img_name in images:\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    self.samples.append((img_path, current_idx))\n",
        "                    \n",
        "            except (ConnectionAbortedError, OSError, PermissionError) as e:\n",
        "                print(f\"Warning: Skipping folder '{folder}' due to error: {e}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Unexpected error with folder '{folder}': {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"Total samples: {len(self.samples)}\")\n",
        "        print(f\"Number of classes: {len(self.classes)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            # Return a dummy image\n",
        "            dummy_image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "            if self.transform:\n",
        "                dummy_image = self.transform(dummy_image)\n",
        "            return dummy_image, label\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "print(\"Creating datasets...\")\n",
        "\n",
        "try:\n",
        "    # Load ALL images from each student folder (no limit)\n",
        "    full_dataset = FaceDataset(DATASET_DIR_DRIVE, transform=train_transform, max_samples_per_class=None)\n",
        "\n",
        "    if len(full_dataset) == 0:\n",
        "        raise ValueError(\"Dataset is empty. Please check your dataset directory.\")\n",
        "\n",
        "    # Split dataset\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = int(0.15 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        full_dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # Update test dataset transform\n",
        "    test_dataset.dataset.transform = test_transform\n",
        "    val_dataset.dataset.transform = test_transform\n",
        "\n",
        "    print(f\"[OK] Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Create data loaders with reduced num_workers for Colab\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
        "\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    print(f\"[OK] Number of classes: {num_classes}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n ERROR: Failed to create dataset: {e}\")\n",
        "    print(\"\\nPLEASE FOLLOW THESE STEPS:\")\n",
        "    print(\"1. Upload your face dataset to Google Drive\")\n",
        "    print(\"2. The dataset should be organized as:\")\n",
        "    print(\"   /content/drive/MyDrive/aligned_faces/\")\n",
        "    print(\"     ├── student_001/\")\n",
        "    print(\"     │   ├── image1.jpg\")\n",
        "    print(\"     │   ├── image2.jpg\")\n",
        "    print(\"     │   └── ...\")\n",
        "    print(\"     ├── student_002/\")\n",
        "    print(\"     └── ... (up to 300 folders)\")\n",
        "    print(\"\\n3. Update DATASET_DIR_DRIVE variable if your path is different\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA9HElBFY58u"
      },
      "source": [
        "## 2. Model Definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0r3dNo7Y58v",
        "outputId": "9238299e-424e-4651-f637-60f0e63554b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. Vanilla CNN Model\n",
        "class VanillaCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(VanillaCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # First block\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Second block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Third block\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Fourth block\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((7, 7)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 7 * 7, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# 2. ResNet50-based Model\n",
        "class ResNet50Face(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet50Face, self).__init__()\n",
        "        # Use weights parameter instead of deprecated pretrained\n",
        "        self.backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# 3. Improved CNN with Attention\n",
        "class AttentionCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AttentionCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        attention_weights = self.attention(features)\n",
        "        attended_features = features * attention_weights\n",
        "        output = self.classifier(attended_features)\n",
        "        return output\n",
        "\n",
        "print(\"Models defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration for 200 Epochs with Early Stopping\n",
        "\n",
        "**Training Configuration:**\n",
        "- **Max Epochs**: 200 (có Early Stopping)\n",
        "- **Early Stopping Patience**: 15 epochs\n",
        "- **Min Improvement**: 0.001 (0.1%)\n",
        "- **Learning Rate Scheduler**: ReduceLROnPlateau\n",
        "  - Initial LR: 0.001\n",
        "  - Factor: 0.5 (giảm LR xuống 50%)\n",
        "  - Patience: 7 epochs\n",
        "- **Optimizer**: Adam\n",
        "- **Batch Size**: 32\n",
        "\n",
        "**Benefits:**\n",
        "1. Tự động dừng khi model không cải thiện -> tiết kiệm thời gian\n",
        "2. Lưu best model checkpoint -> đảm bảo không mất kết quả tốt nhất\n",
        "3. Learning rate tự động giảm -> fine-tuning tốt hơn\n",
        "4. Tracking đầy đủ metrics -> phân tích cho nghiên cứu khoa học\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMmu-IfUY58w"
      },
      "source": [
        "## 3. Training and Visualization Utilities (All-in-One)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TLYl48oqY58y",
        "outputId": "2d712a6e-d398-45d0-d5df-53e4a02f44e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All utility functions loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===== EARLY STOPPING CLASS =====\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping để ngăn overfitting\"\"\"\n",
        "    def __init__(self, patience=15, min_delta=0.001, verbose=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Số epochs chờ đợi trước khi dừng\n",
        "            min_delta (float): Mức cải thiện tối thiểu\n",
        "            verbose (bool): Print thông báo\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_epoch = 0\n",
        "        \n",
        "    def __call__(self, val_acc, epoch):\n",
        "        score = val_acc\n",
        "        \n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_epoch = epoch\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter}/{self.patience} (Best: {self.best_score:.2f}% at epoch {self.best_epoch})')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(f'[IMPROVED] Validation accuracy improved: {self.best_score:.2f}% -> {score:.2f}%')\n",
        "            self.best_score = score\n",
        "            self.best_epoch = epoch\n",
        "            self.counter = 0\n",
        "        \n",
        "        return self.early_stop\n",
        "\n",
        "# ===== TRAINING UTILITIES =====\n",
        "def train_model(model, train_loader, val_loader, num_epochs=200, model_name=\"model\", results_dir=\"./results\", patience=15):\n",
        "    \"\"\"\n",
        "    Train a PyTorch model with Early Stopping\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        num_epochs (int): Maximum số epochs\n",
        "        model_name (str): Tên model để save\n",
        "        results_dir (str): Thư mục lưu kết quả\n",
        "        patience (int): Early stopping patience\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    # ReduceLROnPlateau: giảm LR khi val acc không cải thiện\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=7)\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(patience=patience, min_delta=0.001, verbose=True)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    train_accuracies = []\n",
        "    learning_rates = []\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"[TRAINING] {model_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Max Epochs: {num_epochs} | Early Stopping Patience: {patience}\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ===== TRAINING PHASE =====\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total_train += target.size(0)\n",
        "            correct_train += (predicted == target).sum().item()\n",
        "\n",
        "        # ===== VALIDATION PHASE =====\n",
        "        model.eval()\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        val_running_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "                val_running_loss += loss.item()\n",
        "                \n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                total_val += target.size(0)\n",
        "                correct_val += (predicted == target).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "        train_acc = 100. * correct_train / total_train\n",
        "        val_acc = 100. * correct_val / total_val\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "        learning_rates.append(current_lr)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "        # Print progress mỗi 5 epochs hoặc epoch cuối\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0 or epoch == num_epochs - 1:\n",
        "            print(f'Epoch [{epoch+1:3d}/{num_epochs}] | '\n",
        "                  f'Train Loss: {epoch_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
        "                  f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | '\n",
        "                  f'LR: {current_lr:.6f}')\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        scheduler.step(val_acc)\n",
        "        \n",
        "        # Early stopping check\n",
        "        if early_stopping(val_acc, epoch + 1):\n",
        "            print(f'\\n[EARLY STOP] Triggered at epoch {epoch+1}')\n",
        "            print(f'Best Val Accuracy: {early_stopping.best_score:.2f}% at epoch {early_stopping.best_epoch}')\n",
        "            break\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"[COMPLETED] Training {model_name} completed!\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total Training Time: {training_time/60:.2f} minutes\")\n",
        "    print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"Total Epochs Trained: {len(train_losses)}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Save best model\n",
        "    best_model_path = os.path.join(results_dir, f'{model_name}_best_model.pth')\n",
        "    torch.save(best_model_state, best_model_path)\n",
        "    print(f\"[SAVED] Best model saved to: {best_model_path}\")\n",
        "    \n",
        "    # Load best model for final evaluation\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'training_time': training_time,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'learning_rates': learning_rates,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'total_epochs': len(train_losses),\n",
        "        'early_stopped': early_stopping.early_stop,\n",
        "        'best_epoch': early_stopping.best_epoch\n",
        "    }\n",
        "\n",
        "def evaluate_model(model, test_loader, model_name=\"model\"):\n",
        "    \"\"\"Evaluate a PyTorch model\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy * 100,\n",
        "        'precision': precision * 100,\n",
        "        'recall': recall * 100,\n",
        "        'f1_score': f1 * 100,\n",
        "        'inference_time': inference_time,\n",
        "        'predictions': all_predictions,\n",
        "        'targets': all_targets\n",
        "    }\n",
        "\n",
        "def calculate_model_size(model):\n",
        "    \"\"\"Calculate model size in MB\"\"\"\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "    return size_all_mb\n",
        "\n",
        "class AdaBoostFaceClassifier:\n",
        "    def __init__(self, n_estimators=50):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.model = None\n",
        "\n",
        "    def extract_features(self, images):\n",
        "        \"\"\"Extract features from images for AdaBoost\"\"\"\n",
        "        features = []\n",
        "\n",
        "        for img in images:\n",
        "            # Convert tensor to numpy if needed\n",
        "            if torch.is_tensor(img):\n",
        "                img = img.permute(1, 2, 0).numpy()\n",
        "                img = (img * 255).astype(np.uint8)\n",
        "\n",
        "            # Convert to grayscale\n",
        "            if len(img.shape) == 3:\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            else:\n",
        "                gray = img\n",
        "\n",
        "            # Resize to fixed size\n",
        "            gray = cv2.resize(gray, (64, 64))\n",
        "\n",
        "            # Extract multiple types of features\n",
        "            feature_vector = []\n",
        "\n",
        "            # 1. Raw pixel values (subsampled)\n",
        "            pixel_features = gray[::4, ::4].flatten()\n",
        "            feature_vector.extend(pixel_features)\n",
        "\n",
        "            # 2. Histogram features\n",
        "            hist = cv2.calcHist([gray], [0], None, [16], [0, 256])\n",
        "            feature_vector.extend(hist.flatten())\n",
        "\n",
        "            # 3. LBP-like features (simplified)\n",
        "            lbp_features = []\n",
        "            for i in range(1, gray.shape[0]-1):\n",
        "                for j in range(1, gray.shape[1]-1):\n",
        "                    center = gray[i, j]\n",
        "                    pattern = 0\n",
        "                    pattern += (gray[i-1, j-1] > center) * 1\n",
        "                    pattern += (gray[i-1, j] > center) * 2\n",
        "                    pattern += (gray[i-1, j+1] > center) * 4\n",
        "                    pattern += (gray[i, j+1] > center) * 8\n",
        "                    lbp_features.append(pattern)\n",
        "\n",
        "            # Sample LBP features\n",
        "            if len(lbp_features) > 100:\n",
        "                lbp_features = lbp_features[::len(lbp_features)//100][:100]\n",
        "            feature_vector.extend(lbp_features)\n",
        "\n",
        "            features.append(feature_vector)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def fit(self, train_loader, val_loader=None):\n",
        "        \"\"\"Train AdaBoost classifier\"\"\"\n",
        "        print(\"Extracting features for AdaBoost training...\")\n",
        "\n",
        "        # Extract features from training data\n",
        "        X_train, y_train = [], []\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Processing batch {batch_idx}/{len(train_loader)}\")\n",
        "\n",
        "            # Denormalize images\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "            images = images * std + mean\n",
        "\n",
        "            batch_features = self.extract_features(images)\n",
        "            X_train.extend(batch_features)\n",
        "            y_train.extend(labels.numpy())\n",
        "\n",
        "            # Limit data for faster training\n",
        "            if len(X_train) > 2000:\n",
        "                break\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        print(f\"Training AdaBoost with {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
        "\n",
        "        # Train AdaBoost\n",
        "        # Use 'estimator' instead of deprecated 'base_estimator' (sklearn 1.2+)\n",
        "        self.model = AdaBoostClassifier(\n",
        "            estimator=DecisionTreeClassifier(max_depth=1),\n",
        "            n_estimators=self.n_estimators,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.training_time = time.time() - start_time\n",
        "\n",
        "        print(f\"AdaBoost training completed in {self.training_time:.2f} seconds\")\n",
        "\n",
        "        return self.training_time\n",
        "\n",
        "    def predict(self, test_loader):\n",
        "        \"\"\"Make predictions on test data\"\"\"\n",
        "        print(\"Extracting features for AdaBoost prediction...\")\n",
        "\n",
        "        X_test, y_test = [], []\n",
        "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "            # Denormalize images\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "            images = images * std + mean\n",
        "\n",
        "            batch_features = self.extract_features(images)\n",
        "            X_test.extend(batch_features)\n",
        "            y_test.extend(labels.numpy())\n",
        "\n",
        "        X_test = np.array(X_test)\n",
        "        y_test = np.array(y_test)\n",
        "\n",
        "        start_time = time.time()\n",
        "        predictions = self.model.predict(X_test)\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        return predictions, y_test, inference_time\n",
        "\n",
        "# ===== VISUALIZATION UTILITIES =====\n",
        "def create_individual_training_plots(training_curves, results_dir):\n",
        "    \"\"\"Tạo biểu đồ training riêng cho từng model (chi tiết cho nghiên cứu khoa học)\"\"\"\n",
        "    \n",
        "    cnn_models = [m for m in training_curves.keys() if m != 'AdaBoost']\n",
        "    \n",
        "    for model_name in cnn_models:\n",
        "        if model_name not in training_curves:\n",
        "            continue\n",
        "            \n",
        "        curves = training_curves[model_name]\n",
        "        epochs = range(1, len(curves['train_accuracies']) + 1)\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        fig.suptitle(f'{model_name} - Detailed Training Analysis', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # 1. Accuracy Curves\n",
        "        ax = axes[0, 0]\n",
        "        ax.plot(epochs, curves['train_accuracies'], 'b-', linewidth=2, label='Train Accuracy', marker='o', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "        ax.plot(epochs, curves['val_accuracies'], 'r-', linewidth=2, label='Validation Accuracy', marker='s', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "        ax.set_xlabel('Epoch', fontsize=12)\n",
        "        ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "        ax.set_title('Training vs Validation Accuracy', fontsize=13, fontweight='bold')\n",
        "        ax.legend(loc='lower right', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        # Đánh dấu best epoch\n",
        "        if 'best_epoch' in curves:\n",
        "            best_epoch = curves['best_epoch']\n",
        "            if best_epoch <= len(epochs):\n",
        "                ax.axvline(x=best_epoch, color='green', linestyle='--', linewidth=2, alpha=0.7, label=f'Best Epoch: {best_epoch}')\n",
        "                ax.legend(loc='lower right', fontsize=10)\n",
        "        \n",
        "        # 2. Loss Curves\n",
        "        ax = axes[0, 1]\n",
        "        ax.plot(epochs, curves['train_losses'], 'b-', linewidth=2, label='Train Loss', marker='o', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "        if 'val_losses' in curves:\n",
        "            ax.plot(epochs, curves['val_losses'], 'r-', linewidth=2, label='Validation Loss', marker='s', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "        ax.set_xlabel('Epoch', fontsize=12)\n",
        "        ax.set_ylabel('Loss', fontsize=12)\n",
        "        ax.set_title('Training vs Validation Loss', fontsize=13, fontweight='bold')\n",
        "        ax.legend(loc='upper right', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        # 3. Learning Rate Schedule\n",
        "        ax = axes[1, 0]\n",
        "        if 'learning_rates' in curves:\n",
        "            ax.plot(epochs, curves['learning_rates'], 'g-', linewidth=2, marker='o', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "            ax.set_xlabel('Epoch', fontsize=12)\n",
        "            ax.set_ylabel('Learning Rate', fontsize=12)\n",
        "            ax.set_title('Learning Rate Schedule', fontsize=13, fontweight='bold')\n",
        "            ax.set_yscale('log')\n",
        "            ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, 'Learning Rate data not available', ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
        "        \n",
        "        # 4. Overfitting Analysis (Train-Val Gap)\n",
        "        ax = axes[1, 1]\n",
        "        gap = np.array(curves['train_accuracies']) - np.array(curves['val_accuracies'])\n",
        "        ax.plot(epochs, gap, 'purple', linewidth=2, marker='o', markersize=3, markevery=max(1, len(epochs)//20))\n",
        "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
        "        ax.fill_between(epochs, 0, gap, where=(gap >= 0), alpha=0.3, color='red', label='Overfitting')\n",
        "        ax.set_xlabel('Epoch', fontsize=12)\n",
        "        ax.set_ylabel('Accuracy Gap (Train - Val) %', fontsize=12)\n",
        "        ax.set_title('Overfitting Analysis', fontsize=13, fontweight='bold')\n",
        "        ax.legend(loc='upper right', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(results_dir, f'{model_name.lower().replace(\" \", \"_\")}_training_analysis.png')\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"[SAVED] {save_path}\")\n",
        "\n",
        "def create_comparison_charts(all_results, training_curves, results_dir):\n",
        "    \"\"\"Tạo biểu đồ so sánh tổng quan giữa các models\"\"\"\n",
        "\n",
        "    plt.style.use('default')\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    models = list(all_results.keys())\n",
        "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']  # Modern colors\n",
        "\n",
        "    # 1. Test Accuracy Comparison\n",
        "    plt.subplot(3, 3, 1)\n",
        "    accuracies = [all_results[model]['test_accuracy'] for model in models]\n",
        "    bars = plt.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    plt.title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Accuracy (%)', fontsize=11)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylim([min(accuracies) - 5, 100])\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                 f'{height:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # 2. Training Time Comparison\n",
        "    plt.subplot(3, 3, 2)\n",
        "    training_times = [all_results[model]['training_time']/60 for model in models]\n",
        "    bars = plt.bar(models, training_times, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    plt.title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Time (minutes)', fontsize=11)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                 f'{height:.1f}m', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # 3. Model Size Comparison\n",
        "    plt.subplot(3, 3, 3)\n",
        "    model_sizes = [all_results[model]['model_size_mb'] for model in models]\n",
        "    bars = plt.bar(models, model_sizes, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    plt.title('Model Size Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Size (MB)', fontsize=11)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                 f'{height:.1f}MB', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # 4. Precision-Recall-F1 Comparison\n",
        "    plt.subplot(3, 3, 4)\n",
        "    metrics = ['test_precision', 'test_recall', 'test_f1']\n",
        "    metric_labels = ['Precision', 'Recall', 'F1-Score']\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.25\n",
        "\n",
        "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
        "        values = [all_results[model][metric] for model in models]\n",
        "        plt.bar(x + i*width, values, width, label=label, edgecolor='black', linewidth=1)\n",
        "\n",
        "    plt.title('Precision, Recall, F1-Score Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Score (%)', fontsize=11)\n",
        "    plt.xlabel('Models', fontsize=11)\n",
        "    plt.xticks(x + width, models, rotation=45, ha='right')\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    plt.ylim([0, 105])\n",
        "\n",
        "    # 5. Inference Time Comparison\n",
        "    plt.subplot(3, 3, 5)\n",
        "    inference_times = [all_results[model]['inference_time'] for model in models]\n",
        "    bars = plt.bar(models, inference_times, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    plt.title('Inference Time Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Time (seconds)', fontsize=11)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                 f'{height:.3f}s', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # 6. Total Epochs Trained\n",
        "    plt.subplot(3, 3, 6)\n",
        "    epochs_trained = [all_results[model].get('total_epochs', 0) for model in models]\n",
        "    bars = plt.bar(models, epochs_trained, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    plt.title('Total Epochs Trained', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Epochs', fontsize=11)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        if height > 0:\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                     f'{int(height)}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # 7-9. Training Curves for CNN models\n",
        "    cnn_models = ['Vanilla CNN', 'ResNet50', 'Attention CNN']\n",
        "    for idx, model_name in enumerate(cnn_models):\n",
        "        plt.subplot(3, 3, 7 + idx)\n",
        "        if model_name in training_curves:\n",
        "            epochs = range(1, len(training_curves[model_name]['train_accuracies']) + 1)\n",
        "            plt.plot(epochs, training_curves[model_name]['train_accuracies'], 'b-', linewidth=2, label='Train', alpha=0.8)\n",
        "            plt.plot(epochs, training_curves[model_name]['val_accuracies'], 'r-', linewidth=2, label='Validation', alpha=0.8)\n",
        "            \n",
        "            # Mark best epoch\n",
        "            if 'best_epoch' in training_curves[model_name]:\n",
        "                best_epoch = training_curves[model_name]['best_epoch']\n",
        "                if best_epoch <= len(epochs):\n",
        "                    plt.axvline(x=best_epoch, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
        "            \n",
        "            plt.title(f'{model_name} - Learning Curves', fontsize=12, fontweight='bold')\n",
        "            plt.xlabel('Epoch', fontsize=10)\n",
        "            plt.ylabel('Accuracy (%)', fontsize=10)\n",
        "            plt.legend(fontsize=9, loc='lower right')\n",
        "            plt.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    chart_path = os.path.join(results_dir, 'model_comparison_summary.png')\n",
        "    plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"[SAVED] {chart_path}\")\n",
        "\n",
        "    return chart_path\n",
        "\n",
        "def create_detailed_analysis(all_results, training_curves, results_dir, dataset_info):\n",
        "    \"\"\"Create detailed analysis report\"\"\"\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame(all_results).T\n",
        "    results_df = results_df.round(2)\n",
        "\n",
        "    # Save results to CSV\n",
        "    csv_path = os.path.join(results_dir, 'model_comparison_results.csv')\n",
        "    results_df.to_csv(csv_path)\n",
        "\n",
        "    # Generate recommendations\n",
        "    best_accuracy_model = max(all_results.keys(), key=lambda x: all_results[x]['test_accuracy'])\n",
        "    best_speed_model = min(all_results.keys(), key=lambda x: all_results[x]['inference_time'])\n",
        "    most_efficient_model = min(all_results.keys(), key=lambda x: all_results[x]['model_size_mb'])\n",
        "\n",
        "    # Calculate balanced score\n",
        "    balanced_scores = {}\n",
        "    for model in all_results.keys():\n",
        "        acc = all_results[model]['test_accuracy']\n",
        "        size = all_results[model]['model_size_mb']\n",
        "        time = all_results[model]['inference_time']\n",
        "        balanced_scores[model] = acc / (size + time * 100)\n",
        "\n",
        "    best_balanced = max(balanced_scores.keys(), key=lambda x: balanced_scores[x])\n",
        "\n",
        "    # Save complete analysis as JSON\n",
        "    analysis_report = {\n",
        "        'experiment_info': {\n",
        "            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'dataset_path': dataset_info.get('dataset_path', ''),\n",
        "            'num_classes': dataset_info.get('num_classes', 0),\n",
        "            'train_samples': dataset_info.get('train_samples', 0),\n",
        "            'val_samples': dataset_info.get('val_samples', 0),\n",
        "            'test_samples': dataset_info.get('test_samples', 0),\n",
        "            'device': dataset_info.get('device', 'CPU')\n",
        "        },\n",
        "        'model_results': all_results,\n",
        "        'training_curves': training_curves\n",
        "    }\n",
        "\n",
        "    json_path = os.path.join(results_dir, 'complete_analysis.json')\n",
        "    with open(json_path, 'w') as f:\n",
        "        # Convert numpy arrays to lists for JSON serialization\n",
        "        def convert_numpy(obj):\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            elif isinstance(obj, dict):\n",
        "                return {key: convert_numpy(value) for key, value in obj.items()}\n",
        "            elif isinstance(obj, list):\n",
        "                return [convert_numpy(item) for item in obj]\n",
        "            else:\n",
        "                return obj\n",
        "\n",
        "        json.dump(convert_numpy(analysis_report), f, indent=2)\n",
        "\n",
        "    # Create summary report\n",
        "    summary_report = f\"\"\"# FACE DETECTION MODEL COMPARISON REPORT\n",
        "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## EXPERIMENT SETUP\n",
        "- Dataset: {dataset_info.get('dataset_path', 'N/A')}\n",
        "- Number of Classes: {dataset_info.get('num_classes', 'N/A')}\n",
        "- Training Samples: {dataset_info.get('train_samples', 'N/A')}\n",
        "- Validation Samples: {dataset_info.get('val_samples', 'N/A')}\n",
        "- Test Samples: {dataset_info.get('test_samples', 'N/A')}\n",
        "- Device: {dataset_info.get('device', 'N/A')}\n",
        "\n",
        "## MODELS COMPARED\n",
        "1. Vanilla CNN - Custom lightweight CNN architecture\n",
        "2. ResNet50 - Pre-trained ResNet50 with transfer learning\n",
        "3. Attention CNN - CNN with attention mechanism\n",
        "4. AdaBoost - Classical machine learning with hand-crafted features\n",
        "\n",
        "## RESULTS SUMMARY\n",
        "\n",
        "| Model | Test Accuracy | Training Time | Inference Time | Model Size | F1-Score |\n",
        "|-------|---------------|---------------|----------------|------------|----------|\n",
        "\"\"\"\n",
        "\n",
        "    for model_name, results in all_results.items():\n",
        "        summary_report += f\"| {model_name} | {results['test_accuracy']:.2f}% | {results['training_time']/60:.1f}m | {results['inference_time']:.3f}s | {results['model_size_mb']:.1f}MB | {results['test_f1']:.2f}% |\\n\"\n",
        "\n",
        "    summary_report += f\"\"\"\n",
        "\n",
        "## KEY FINDINGS\n",
        "- Best Accuracy: {best_accuracy_model} ({all_results[best_accuracy_model]['test_accuracy']:.2f}%)\n",
        "- Fastest Inference: {best_speed_model} ({all_results[best_speed_model]['inference_time']:.3f}s)\n",
        "- Most Compact: {most_efficient_model} ({all_results[most_efficient_model]['model_size_mb']:.1f}MB)\n",
        "- Best Balanced: {best_balanced}\n",
        "\n",
        "## RECOMMENDATIONS\n",
        "1. For highest accuracy: Use {best_accuracy_model}\n",
        "2. For real-time applications: Use {best_speed_model}\n",
        "3. For mobile deployment: Use {most_efficient_model}\n",
        "4. For balanced performance: Use {best_balanced}\n",
        "\n",
        "Generated by Face Detection Comparison Pipeline\n",
        "\"\"\"\n",
        "\n",
        "    # Save summary report\n",
        "    summary_path = os.path.join(results_dir, 'SUMMARY_REPORT.md')\n",
        "    with open(summary_path, 'w') as f:\n",
        "        f.write(summary_report)\n",
        "\n",
        "    return {\n",
        "        'summary_path': summary_path,\n",
        "        'csv_path': csv_path,\n",
        "        'json_path': json_path,\n",
        "        'best_models': {\n",
        "            'accuracy': best_accuracy_model,\n",
        "            'speed': best_speed_model,\n",
        "            'efficiency': most_efficient_model,\n",
        "            'balanced': best_balanced\n",
        "        }\n",
        "    }\n",
        "\n",
        "def print_results_summary(all_results):\n",
        "    \"\"\"Print a formatted summary of results\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL RESULTS COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create and print results dataframe\n",
        "    results_df = pd.DataFrame(all_results).T\n",
        "    results_df = results_df.round(2)\n",
        "    print(results_df)\n",
        "    print(\"=\"*80)\n",
        "\n",
        "print(\"[OK] All utility functions loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACCELzMhY580"
      },
      "source": [
        "## 4. Run All Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r69nK0yjY580",
        "outputId": "2edc577b-1cc9-411b-9f9a-3143f119a17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model training and evaluation...\n",
            "Dataset: 294 classes\n",
            "Train size: 4116\n",
            "Validation size: 882\n",
            "Test size: 882\n",
            "==================================================\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store all results\n",
        "all_results = {}\n",
        "training_curves = {}\n",
        "\n",
        "print(\"Starting model training and evaluation...\")\n",
        "print(f\"Dataset: {num_classes} classes\")\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Dataset info for analysis\n",
        "dataset_info = {\n",
        "    'dataset_path': DATASET_DIR_DRIVE,\n",
        "    'num_classes': num_classes,\n",
        "    'train_samples': len(train_dataset),\n",
        "    'val_samples': len(val_dataset),\n",
        "    'test_samples': len(test_dataset),\n",
        "    'device': 'GPU' if torch.cuda.is_available() else 'CPU'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebvt7xBhY581",
        "outputId": "c6a50acb-9b0b-494a-fcf5-92de687e2d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. Training Vanilla CNN...\n"
          ]
        }
      ],
      "source": [
        "# ===== 1. TRAIN VANILLA CNN =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL 1/4: VANILLA CNN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "vanilla_cnn = VanillaCNN(num_classes)\n",
        "vanilla_results = train_model(\n",
        "    model=vanilla_cnn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=200,\n",
        "    model_name=\"vanilla_cnn\",\n",
        "    results_dir=RESULTS_DIR,\n",
        "    patience=15  # Early stopping patience\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\n[EVAL] Evaluating Vanilla CNN on test set...\")\n",
        "vanilla_eval = evaluate_model(vanilla_results['model'], test_loader, \"vanilla_cnn\")\n",
        "\n",
        "# Store results\n",
        "all_results['Vanilla CNN'] = {\n",
        "    'training_time': vanilla_results['training_time'],\n",
        "    'best_val_accuracy': vanilla_results['best_val_acc'],\n",
        "    'test_accuracy': vanilla_eval['accuracy'],\n",
        "    'test_precision': vanilla_eval['precision'],\n",
        "    'test_recall': vanilla_eval['recall'],\n",
        "    'test_f1': vanilla_eval['f1_score'],\n",
        "    'inference_time': vanilla_eval['inference_time'],\n",
        "    'model_size_mb': calculate_model_size(vanilla_results['model']),\n",
        "    'total_epochs': vanilla_results['total_epochs'],\n",
        "    'early_stopped': vanilla_results['early_stopped'],\n",
        "    'best_epoch': vanilla_results['best_epoch']\n",
        "}\n",
        "\n",
        "training_curves['Vanilla CNN'] = {\n",
        "    'train_losses': vanilla_results['train_losses'],\n",
        "    'val_losses': vanilla_results['val_losses'],\n",
        "    'train_accuracies': vanilla_results['train_accuracies'],\n",
        "    'val_accuracies': vanilla_results['val_accuracies'],\n",
        "    'learning_rates': vanilla_results['learning_rates'],\n",
        "    'best_epoch': vanilla_results['best_epoch']\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[RESULTS] VANILLA CNN:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {vanilla_eval['accuracy']:.2f}%\")\n",
        "print(f\"Test Precision: {vanilla_eval['precision']:.2f}%\")\n",
        "print(f\"Test Recall: {vanilla_eval['recall']:.2f}%\")\n",
        "print(f\"Test F1-Score: {vanilla_eval['f1_score']:.2f}%\")\n",
        "print(f\"Training Time: {vanilla_results['training_time']/60:.2f} minutes\")\n",
        "print(f\"Total Epochs: {vanilla_results['total_epochs']}\")\n",
        "print(f\"Model Size: {calculate_model_size(vanilla_results['model']):.2f} MB\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# Clear GPU memory\n",
        "del vanilla_cnn, vanilla_results\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqvw7rryY581"
      },
      "outputs": [],
      "source": [
        "# ===== 2. TRAIN RESNET50 =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL 2/4: RESNET50 (Transfer Learning)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "resnet_model = ResNet50Face(num_classes)\n",
        "resnet_results = train_model(\n",
        "    model=resnet_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=200,\n",
        "    model_name=\"resnet50\",\n",
        "    results_dir=RESULTS_DIR,\n",
        "    patience=15\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\n[EVAL] Evaluating ResNet50 on test set...\")\n",
        "resnet_eval = evaluate_model(resnet_results['model'], test_loader, \"resnet50\")\n",
        "\n",
        "# Store results\n",
        "all_results['ResNet50'] = {\n",
        "    'training_time': resnet_results['training_time'],\n",
        "    'best_val_accuracy': resnet_results['best_val_acc'],\n",
        "    'test_accuracy': resnet_eval['accuracy'],\n",
        "    'test_precision': resnet_eval['precision'],\n",
        "    'test_recall': resnet_eval['recall'],\n",
        "    'test_f1': resnet_eval['f1_score'],\n",
        "    'inference_time': resnet_eval['inference_time'],\n",
        "    'model_size_mb': calculate_model_size(resnet_results['model']),\n",
        "    'total_epochs': resnet_results['total_epochs'],\n",
        "    'early_stopped': resnet_results['early_stopped'],\n",
        "    'best_epoch': resnet_results['best_epoch']\n",
        "}\n",
        "\n",
        "training_curves['ResNet50'] = {\n",
        "    'train_losses': resnet_results['train_losses'],\n",
        "    'val_losses': resnet_results['val_losses'],\n",
        "    'train_accuracies': resnet_results['train_accuracies'],\n",
        "    'val_accuracies': resnet_results['val_accuracies'],\n",
        "    'learning_rates': resnet_results['learning_rates'],\n",
        "    'best_epoch': resnet_results['best_epoch']\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[RESULTS] RESNET50:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {resnet_eval['accuracy']:.2f}%\")\n",
        "print(f\"Test Precision: {resnet_eval['precision']:.2f}%\")\n",
        "print(f\"Test Recall: {resnet_eval['recall']:.2f}%\")\n",
        "print(f\"Test F1-Score: {resnet_eval['f1_score']:.2f}%\")\n",
        "print(f\"Training Time: {resnet_results['training_time']/60:.2f} minutes\")\n",
        "print(f\"Total Epochs: {resnet_results['total_epochs']}\")\n",
        "print(f\"Model Size: {calculate_model_size(resnet_results['model']):.2f} MB\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# Clear GPU memory\n",
        "del resnet_model, resnet_results\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IhzRXLEY583"
      },
      "outputs": [],
      "source": [
        "# ===== 3. TRAIN ATTENTION CNN =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL 3/4: ATTENTION CNN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "attention_cnn = AttentionCNN(num_classes)\n",
        "attention_results = train_model(\n",
        "    model=attention_cnn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=200,\n",
        "    model_name=\"attention_cnn\",\n",
        "    results_dir=RESULTS_DIR,\n",
        "    patience=15\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\n[EVAL] Evaluating Attention CNN on test set...\")\n",
        "attention_eval = evaluate_model(attention_results['model'], test_loader, \"attention_cnn\")\n",
        "\n",
        "# Store results\n",
        "all_results['Attention CNN'] = {\n",
        "    'training_time': attention_results['training_time'],\n",
        "    'best_val_accuracy': attention_results['best_val_acc'],\n",
        "    'test_accuracy': attention_eval['accuracy'],\n",
        "    'test_precision': attention_eval['precision'],\n",
        "    'test_recall': attention_eval['recall'],\n",
        "    'test_f1': attention_eval['f1_score'],\n",
        "    'inference_time': attention_eval['inference_time'],\n",
        "    'model_size_mb': calculate_model_size(attention_results['model']),\n",
        "    'total_epochs': attention_results['total_epochs'],\n",
        "    'early_stopped': attention_results['early_stopped'],\n",
        "    'best_epoch': attention_results['best_epoch']\n",
        "}\n",
        "\n",
        "training_curves['Attention CNN'] = {\n",
        "    'train_losses': attention_results['train_losses'],\n",
        "    'val_losses': attention_results['val_losses'],\n",
        "    'train_accuracies': attention_results['train_accuracies'],\n",
        "    'val_accuracies': attention_results['val_accuracies'],\n",
        "    'learning_rates': attention_results['learning_rates'],\n",
        "    'best_epoch': attention_results['best_epoch']\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[RESULTS] ATTENTION CNN:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {attention_eval['accuracy']:.2f}%\")\n",
        "print(f\"Test Precision: {attention_eval['precision']:.2f}%\")\n",
        "print(f\"Test Recall: {attention_eval['recall']:.2f}%\")\n",
        "print(f\"Test F1-Score: {attention_eval['f1_score']:.2f}%\")\n",
        "print(f\"Training Time: {attention_results['training_time']/60:.2f} minutes\")\n",
        "print(f\"Total Epochs: {attention_results['total_epochs']}\")\n",
        "print(f\"Model Size: {calculate_model_size(attention_results['model']):.2f} MB\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# Clear GPU memory\n",
        "del attention_cnn, attention_results\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huwuB24oY583"
      },
      "outputs": [],
      "source": [
        "# ===== 4. TRAIN ADABOOST =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL 4/4: ADABOOST (Classical ML)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "adaboost_model = AdaBoostFaceClassifier(n_estimators=100)\n",
        "ada_training_time = adaboost_model.fit(train_loader, val_loader)\n",
        "\n",
        "# Predict on test set\n",
        "print(\"\\n[EVAL] Evaluating AdaBoost on test set...\")\n",
        "ada_predictions, ada_targets, ada_inference_time = adaboost_model.predict(test_loader)\n",
        "\n",
        "# Calculate metrics\n",
        "ada_accuracy = accuracy_score(ada_targets, ada_predictions)\n",
        "ada_precision, ada_recall, ada_f1, _ = precision_recall_fscore_support(ada_targets, ada_predictions, average='weighted')\n",
        "\n",
        "# Save AdaBoost model to calculate size\n",
        "adaboost_path = os.path.join(RESULTS_DIR, 'adaboost_best_model.pkl')\n",
        "with open(adaboost_path, 'wb') as f:\n",
        "    pickle.dump(adaboost_model, f)\n",
        "\n",
        "# Calculate AdaBoost model size\n",
        "adaboost_size_mb = os.path.getsize(adaboost_path) / (1024 * 1024)\n",
        "\n",
        "# Store results\n",
        "all_results['AdaBoost'] = {\n",
        "    'training_time': ada_training_time,\n",
        "    'best_val_accuracy': 0,  # Not applicable for AdaBoost\n",
        "    'test_accuracy': ada_accuracy * 100,\n",
        "    'test_precision': ada_precision * 100,\n",
        "    'test_recall': ada_recall * 100,\n",
        "    'test_f1': ada_f1 * 100,\n",
        "    'inference_time': ada_inference_time,\n",
        "    'model_size_mb': adaboost_size_mb,\n",
        "    'total_epochs': 100,  # n_estimators\n",
        "    'early_stopped': False,\n",
        "    'best_epoch': 100\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"[RESULTS] ADABOOST:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Test Accuracy: {ada_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Precision: {ada_precision * 100:.2f}%\")\n",
        "print(f\"Test Recall: {ada_recall * 100:.2f}%\")\n",
        "print(f\"Test F1-Score: {ada_f1 * 100:.2f}%\")\n",
        "print(f\"Training Time: {ada_training_time/60:.2f} minutes\")\n",
        "print(f\"Model Size: {adaboost_size_mb:.2f} MB\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL 4 MODELS TRAINED SUCCESSFULLY!\")\n",
        "print(\"=\"*80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFtPlmtFY584"
      },
      "source": [
        "## 5. Results Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Swn257gY584"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[ANALYSIS] GENERATING COMPREHENSIVE ANALYSIS & VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Print results summary\n",
        "print(\"\\n[1] Results Summary Table:\")\n",
        "print(\"-\" * 80)\n",
        "print_results_summary(all_results)\n",
        "\n",
        "# 2. Create individual training plots (chi tiết cho từng model)\n",
        "print(\"\\n[2] Creating Individual Training Analysis Plots...\")\n",
        "print(\"-\" * 80)\n",
        "create_individual_training_plots(training_curves, RESULTS_DIR)\n",
        "\n",
        "# 3. Create comparison charts\n",
        "print(\"\\n[3] Creating Model Comparison Charts...\")\n",
        "print(\"-\" * 80)\n",
        "chart_path = create_comparison_charts(all_results, training_curves, RESULTS_DIR)\n",
        "\n",
        "# 4. Create detailed analysis report\n",
        "print(\"\\n[4] Generating Detailed Analysis Report...\")\n",
        "print(\"-\" * 80)\n",
        "analysis_results = create_detailed_analysis(all_results, training_curves, RESULTS_DIR, dataset_info)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"[COMPLETED] EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\n[FILES] All results saved to: {RESULTS_DIR}\")\n",
        "print(f\"\\n[REPORT] Summary report: {analysis_results['summary_path']}\")\n",
        "print(f\"[CSV] CSV results: {analysis_results['csv_path']}\")\n",
        "print(f\"[JSON] JSON analysis: {analysis_results['json_path']}\")\n",
        "\n",
        "# Print recommendations for research paper\n",
        "best_models = analysis_results['best_models']\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"[RECOMMENDATIONS] FOR STUDENT ATTENDANCE SYSTEM\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\n[1] FOR HIGHEST ACCURACY:\")\n",
        "print(f\"   Model: {best_models['accuracy']}\")\n",
        "print(f\"   Accuracy: {all_results[best_models['accuracy']]['test_accuracy']:.2f}%\")\n",
        "print(f\"   Use case: Khi cần độ chính xác cao nhất, ít quan tâm tốc độ\")\n",
        "\n",
        "print(f\"\\n[2] FOR REAL-TIME APPLICATIONS:\")\n",
        "print(f\"   Model: {best_models['speed']}\")\n",
        "print(f\"   Inference Time: {all_results[best_models['speed']]['inference_time']:.3f}s\")\n",
        "print(f\"   Use case: Điểm danh thời gian thực, nhiều sinh viên cùng lúc\")\n",
        "\n",
        "print(f\"\\n[3] FOR MOBILE/EDGE DEPLOYMENT:\")\n",
        "print(f\"   Model: {best_models['efficiency']}\")\n",
        "print(f\"   Model Size: {all_results[best_models['efficiency']]['model_size_mb']:.2f} MB\")\n",
        "print(f\"   Use case: Chạy trên thiết bị di động, Raspberry Pi\")\n",
        "\n",
        "print(f\"\\n[4] FOR BALANCED PERFORMANCE:\")\n",
        "print(f\"   Model: {best_models['balanced']}\")\n",
        "print(f\"   Use case: Cân bằng giữa accuracy, speed và model size\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"[FILES] CREATED FOR RESEARCH PAPER:\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "files_list = [\n",
        "    (\"Model Weights\", [\n",
        "        \"vanilla_cnn_best_model.pth\",\n",
        "        \"resnet50_best_model.pth\",\n",
        "        \"attention_cnn_best_model.pth\",\n",
        "        \"adaboost_best_model.pkl\"\n",
        "    ]),\n",
        "    (\"Analysis Reports\", [\n",
        "        \"SUMMARY_REPORT.md\",\n",
        "        \"model_comparison_results.csv\",\n",
        "        \"complete_analysis.json\"\n",
        "    ]),\n",
        "    (\"Visualizations\", [\n",
        "        \"model_comparison_summary.png\",\n",
        "        \"vanilla_cnn_training_analysis.png\",\n",
        "        \"resnet50_training_analysis.png\",\n",
        "        \"attention_cnn_training_analysis.png\",\n",
        "        \"detailed_analysis.png\"\n",
        "    ])\n",
        "]\n",
        "\n",
        "for category, files in files_list:\n",
        "    print(f\"\\n[{category}]:\")\n",
        "    for file in files:\n",
        "        print(f\"   - {file}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"[TIP] Use these files for your research paper!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(\"\\n[SECTIONS] Suggested sections:\")\n",
        "print(\"   - ABSTRACT: Use summary statistics from CSV\")\n",
        "print(\"   - METHODOLOGY: Refer to model architectures and training configs\")\n",
        "print(\"   - RESULTS: Use comparison charts and individual training plots\")\n",
        "print(\"   - DISCUSSION: Analyze overfitting, convergence, early stopping behavior\")\n",
        "print(\"   - CONCLUSION: Use recommendations for different deployment scenarios\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"READY FOR RESEARCH PAPER WRITING!\")\n",
        "print(f\"{'='*80}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edtMJEGgY584"
      },
      "source": [
        "## 6.Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGxX3Dy7Y584"
      },
      "outputs": [],
      "source": [
        "# Optional: Create confusion matrices for best performing models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Get the best accuracy model results\n",
        "best_model_name = analysis_results['best_models']['accuracy']\n",
        "print(f\"Creating detailed analysis for best model: {best_model_name}\")\n",
        "\n",
        "# Load the best model and get predictions\n",
        "if best_model_name != 'AdaBoost':\n",
        "    # For CNN models, we need to re-evaluate to get predictions\n",
        "    print(f\"Loading {best_model_name} for confusion matrix generation...\")\n",
        "\n",
        "    # Map model names to their classes\n",
        "    model_mapping = {\n",
        "        'Vanilla CNN': VanillaCNN,\n",
        "        'ResNet50': ResNet50Face,\n",
        "        'Attention CNN': AttentionCNN\n",
        "    }\n",
        "\n",
        "    if best_model_name in model_mapping:\n",
        "        # Load the saved model\n",
        "        model_class = model_mapping[best_model_name]\n",
        "        model = model_class(num_classes)\n",
        "        model_path = os.path.join(RESULTS_DIR, f'{best_model_name.lower().replace(\" \", \"_\")}_model.pth')\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "            eval_results = evaluate_model(model, test_loader, best_model_name)\n",
        "            predictions = eval_results['predictions']\n",
        "            targets = eval_results['targets']\n",
        "        else:\n",
        "            print(f\"Model file not found. Using sample data for visualization.\")\n",
        "            predictions = None\n",
        "            targets = None\n",
        "else:\n",
        "    # For AdaBoost, we already have predictions\n",
        "    predictions = ada_predictions\n",
        "    targets = ada_targets\n",
        "\n",
        "# Create visualizations\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# 1. Confusion Matrix\n",
        "plt.subplot(1, 3, 1)\n",
        "if predictions is not None and targets is not None:\n",
        "    # Use actual predictions for confusion matrix (limited to first 10 classes for visibility)\n",
        "    num_classes_to_show = min(10, num_classes)\n",
        "\n",
        "    # Filter predictions and targets for first N classes\n",
        "    mask = np.array(targets) < num_classes_to_show\n",
        "    filtered_predictions = np.array(predictions)[mask]\n",
        "    filtered_targets = np.array(targets)[mask]\n",
        "\n",
        "    if len(filtered_predictions) > 0:\n",
        "        cm = confusion_matrix(filtered_targets, filtered_predictions, labels=range(num_classes_to_show))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
        "        plt.title(f'Confusion Matrix - {best_model_name}\\n(First {num_classes_to_show} classes)')\n",
        "    else:\n",
        "        # Fallback to sample data\n",
        "        sample_cm = np.random.randint(0, 10, size=(num_classes_to_show, num_classes_to_show))\n",
        "        sns.heatmap(sample_cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title(f'Confusion Matrix - {best_model_name} (Sample)')\n",
        "else:\n",
        "    # Create sample confusion matrix\n",
        "    num_classes_to_show = min(10, num_classes)\n",
        "    sample_cm = np.random.randint(0, 10, size=(num_classes_to_show, num_classes_to_show))\n",
        "    sns.heatmap(sample_cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {best_model_name} (Sample)')\n",
        "\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "\n",
        "# 2. Model Performance Comparison\n",
        "plt.subplot(1, 3, 2)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "models_for_comparison = list(all_results.keys())\n",
        "\n",
        "# Create bar chart for metrics comparison\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.2\n",
        "\n",
        "for i, model in enumerate(models_for_comparison):\n",
        "    values = [\n",
        "        all_results[model]['test_accuracy'],\n",
        "        all_results[model]['test_precision'],\n",
        "        all_results[model]['test_recall'],\n",
        "        all_results[model]['test_f1']\n",
        "    ]\n",
        "    plt.bar(x + i*width, values, width, label=model, alpha=0.8)\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.title('Model Performance Metrics Comparison')\n",
        "plt.xticks(x + width*1.5, metrics)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Efficiency Analysis\n",
        "plt.subplot(1, 3, 3)\n",
        "efficiency_metrics = ['Inference Time (s)', 'Model Size (MB)', 'Training Time (min)']\n",
        "\n",
        "# Normalize values for better visualization\n",
        "norm_data = []\n",
        "for model in models_for_comparison:\n",
        "    norm_data.append([\n",
        "        all_results[model]['inference_time'],\n",
        "        all_results[model]['model_size_mb'],\n",
        "        all_results[model]['training_time'] / 60\n",
        "    ])\n",
        "\n",
        "# Create grouped bar chart\n",
        "x = np.arange(len(models_for_comparison))\n",
        "width = 0.25\n",
        "\n",
        "# Log scale for better visualization of different magnitudes\n",
        "plt.yscale('log')\n",
        "\n",
        "for i, metric in enumerate(efficiency_metrics):\n",
        "    values = [norm_data[j][i] for j in range(len(models_for_comparison))]\n",
        "    plt.bar(x + i*width, values, width, label=metric, alpha=0.8)\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Value (log scale)')\n",
        "plt.title('Model Efficiency Comparison')\n",
        "plt.xticks(x + width, models_for_comparison, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'detailed_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"[COMPLETED] Detailed analysis completed!\")\n",
        "print(f\"[SAVED] Analysis saved to: {os.path.join(RESULTS_DIR, 'detailed_analysis.png')}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
