# HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng Code Cho NghiÃªn Cá»©u Khoa Há»c
## Há»‡ Thá»‘ng Äiá»ƒm Danh Sinh ViÃªn Báº±ng Nháº­n Diá»‡n KhuÃ´n Máº·t

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [Tá»•ng Quan](#tá»•ng-quan)
2. [Cáº¥u HÃ¬nh Training](#cáº¥u-hÃ¬nh-training)
3. [CÃ¡c Model ÄÆ°á»£c So SÃ¡nh](#cÃ¡c-model-Ä‘Æ°á»£c-so-sÃ¡nh)
4. [CÃ¡ch Cháº¡y Code](#cÃ¡ch-cháº¡y-code)
5. [Káº¿t Quáº£ & Biá»ƒu Äá»“](#káº¿t-quáº£--biá»ƒu-Ä‘á»“)
6. [Viáº¿t CÆ¡ Sá»Ÿ LÃ½ Thuyáº¿t](#viáº¿t-cÆ¡-sá»Ÿ-lÃ½-thuyáº¿t)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»”NG QUAN

### Má»¥c TiÃªu NghiÃªn Cá»©u
So sÃ¡nh hiá»‡u nÄƒng cá»§a 4 phÆ°Æ¡ng phÃ¡p nháº­n diá»‡n khuÃ´n máº·t khÃ¡c nhau cho há»‡ thá»‘ng Ä‘iá»ƒm danh sinh viÃªn tá»± Ä‘á»™ng.

### Dataset
- **Sá»‘ lÆ°á»£ng sinh viÃªn**: 294 ngÆ°á»i
- **Sá»‘ áº£nh/sinh viÃªn**: ~20 áº£nh
- **Tá»•ng sá»‘ áº£nh**: 5,880 áº£nh
- **Chia dá»¯ liá»‡u**: 70% Train / 15% Validation / 15% Test

### Metrics ÄÃ¡nh GiÃ¡
1. **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
2. **Precision**: Äá»™ chÃ­nh xÃ¡c cá»§a dá»± Ä‘oÃ¡n positive
3. **Recall**: Kháº£ nÄƒng phÃ¡t hiá»‡n Ä‘Ãºng
4. **F1-Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision & Recall
5. **Training Time**: Thá»i gian training
6. **Inference Time**: Thá»i gian dá»± Ä‘oÃ¡n
7. **Model Size**: KÃ­ch thÆ°á»›c model (MB)

---

## âš™ï¸ CÃC THÃ”NG Sá» TRAINING

### Early Stopping Configuration
```python
patience = 15  # Dá»«ng sau 15 epochs khÃ´ng cáº£i thiá»‡n
min_delta = 0.001  # Cáº£i thiá»‡n tá»‘i thiá»ƒu 0.1%
```

### Learning Rate Schedule
```python
optimizer = Adam(lr=0.001)
scheduler = ReduceLROnPlateau(
    mode='max',        # Maximize validation accuracy
    factor=0.5,        # Giáº£m LR xuá»‘ng 50%
    patience=7,        # Sau 7 epochs khÃ´ng cáº£i thiá»‡n
    verbose=True
)
```

### Training Parameters
- **Max Epochs**: 200
- **Batch Size**: 32
- **Loss Function**: CrossEntropyLoss
- **Data Augmentation**: 
  - Random Horizontal Flip (p=0.5)
  - Random Rotation (Â±10Â°)
  - Color Jitter (brightness, contrast, saturation)

---

## ğŸ¤– CÃC MODEL ÄÆ¯á»¢C SO SÃNH

### 1. Vanilla CNN (Baseline)
```
Architecture:
- 4 Conv Blocks (32â†’64â†’128â†’256 channels)
- BatchNorm + ReLU + MaxPool
- 3 FC Layers (12544â†’512â†’256â†’294)
- Dropout 0.5

Æ¯u Ä‘iá»ƒm: Nháº¹, Ä‘Æ¡n giáº£n
NhÆ°á»£c Ä‘iá»ƒm: Accuracy tháº¥p hÆ¡n
```

### 2. ResNet50 (Transfer Learning)
```
Architecture:
- Pre-trained ResNet50 (ImageNet)
- Replace FC layer (2048â†’294)

Æ¯u Ä‘iá»ƒm: Accuracy cao, convergence nhanh
NhÆ°á»£c Ä‘iá»ƒm: Model size lá»›n (~90MB)
```

### 3. Attention CNN (Custom)
```
Architecture:
- 3 Conv Blocks (VGG-style)
- Attention Mechanism (spatial attention)
- 2 FC Layers (256â†’512â†’294)

Æ¯u Ä‘iá»ƒm: Focus vÃ o vÃ¹ng quan trá»ng, cÃ¢n báº±ng
NhÆ°á»£c Ä‘iá»ƒm: Phá»©c táº¡p hÆ¡n Vanilla CNN
```

### 4. AdaBoost (Classical ML)
```
Features:
- Raw pixels (subsampled 16Ã—16)
- Histogram (16 bins)
- LBP-like features (100 patterns)

Classifier:
- 100 Decision Stumps (max_depth=1)

Æ¯u Ä‘iá»ƒm: KhÃ´ng cáº§n GPU, interpretable
NhÆ°á»£c Ä‘iá»ƒm: Accuracy tháº¥p, feature engineering thá»§ cÃ´ng
```

---

## ğŸš€ CÃCH CHáº Y CODE TRÃŠN GOOGLE COLAB

### BÆ°á»›c 1: Chuáº©n Bá»‹ Dataset

1. Upload dataset lÃªn Google Drive:
```
/content/drive/MyDrive/aligned_faces/
â”œâ”€â”€ student_001/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ student_002/
â””â”€â”€ ...
```

2. Äáº£m báº£o cÃ³ Ã­t nháº¥t 10-20 áº£nh/sinh viÃªn

### BÆ°á»›c 2: Upload Notebook

1. Upload `Face_Detection.ipynb` lÃªn Colab
2. Chá»n Runtime â†’ Change runtime type â†’ **GPU** (T4 hoáº·c L4)

### BÆ°á»›c 3: Cháº¡y Tá»«ng Cell

```python
# Cell 1: Install packages (cháº¡y 1 láº§n)
!pip install -q torch torchvision opencv-python-headless ...

# Cell 2: Mount Drive & Import
from google.colab import drive
drive.mount('/content/drive')

# Cell 3: Check GPU
# XÃ¡c nháº­n cÃ³ GPU NVIDIA

# Cell 5: Load Dataset
# Kiá»ƒm tra sá»‘ lÆ°á»£ng folders vÃ  samples

# Cell 7: Define Models
# Táº¡o 3 CNN architectures

# Cell 9: Training Utilities
# Load EarlyStopping & visualization functions

# Cell 11: Setup
# Initialize dictionaries

# Cell 12-15: Train 4 models (cháº¡y tuáº§n tá»±)
# Má»—i model cÃ³ thá»ƒ máº¥t 15-60 phÃºt

# Cell 17: Generate Reports
# Táº¡o táº¥t cáº£ biá»ƒu Ä‘á»“ vÃ  reports
```

### BÆ°á»›c 4: Theo DÃµi Training

**ChÃº Ã½ cÃ¡c thÃ´ng bÃ¡o:**
```
âœ“ Validation accuracy improved: 85.50% â†’ 87.20%
EarlyStopping counter: 5/15 (Best: 87.20% at epoch 45)
âš ï¸ Early Stopping triggered at epoch 60
```

**Learning Rate giáº£m:**
```
Epoch 00007: reducing learning rate to 0.0005
Epoch 00014: reducing learning rate to 0.00025
```

---

## ğŸ“Š Káº¾T QUáº¢ & BIá»‚U Äá»’

### Files ÄÆ°á»£c Táº¡o Ra

#### 1. Model Weights
```
vanilla_cnn_best_model.pth      # Best checkpoint cá»§a Vanilla CNN
resnet50_best_model.pth         # Best checkpoint cá»§a ResNet50
attention_cnn_best_model.pth    # Best checkpoint cá»§a Attention CNN
adaboost_best_model.pkl         # AdaBoost model
```

#### 2. Biá»ƒu Äá»“ Chi Tiáº¿t Cho Tá»«ng Model
```
vanilla_cnn_training_analysis.png
â”œâ”€â”€ Train vs Val Accuracy
â”œâ”€â”€ Train vs Val Loss
â”œâ”€â”€ Learning Rate Schedule
â””â”€â”€ Overfitting Analysis (Train-Val Gap)

resnet50_training_analysis.png
attention_cnn_training_analysis.png
```

#### 3. Biá»ƒu Äá»“ So SÃ¡nh Tá»•ng Quan
```
model_comparison_summary.png
â”œâ”€â”€ Test Accuracy Comparison
â”œâ”€â”€ Training Time Comparison
â”œâ”€â”€ Model Size Comparison
â”œâ”€â”€ Precision/Recall/F1 Comparison
â”œâ”€â”€ Inference Time Comparison
â”œâ”€â”€ Total Epochs Trained
â””â”€â”€ Learning Curves (3 models)
```

#### 4. Analysis Reports
```
SUMMARY_REPORT.md              # Markdown report
model_comparison_results.csv   # Báº£ng káº¿t quáº£
complete_analysis.json         # Full data
detailed_analysis.png          # Confusion matrix + metrics
```

---

## ğŸ“– VIáº¾T CÆ  Sá» LÃ THUYáº¾T

### 1. ABSTRACT (TÃ³m Táº¯t)

**Dá»¯ liá»‡u tá»«:** `model_comparison_results.csv`

```
NghiÃªn cá»©u nÃ y so sÃ¡nh 4 phÆ°Æ¡ng phÃ¡p nháº­n diá»‡n khuÃ´n máº·t
cho há»‡ thá»‘ng Ä‘iá»ƒm danh sinh viÃªn tá»± Ä‘á»™ng trÃªn dataset 
294 sinh viÃªn (5,880 áº£nh). 

Káº¿t quáº£: ResNet50 Ä‘áº¡t accuracy cao nháº¥t (XX.XX%), 
Vanilla CNN cÃ³ inference time nhanh nháº¥t (X.XXXs),
AdaBoost cÃ³ model size nhá» nháº¥t (XX MB).

Early stopping Ä‘Æ°á»£c Ã¡p dá»¥ng vá»›i patience=15 Ä‘á»ƒ tá»‘i Æ°u
thá»i gian training vÃ  trÃ¡nh overfitting.
```

### 2. RELATED WORK (NghiÃªn Cá»©u LiÃªn Quan)

**TrÃ­ch dáº«n:**
- VGGFace, FaceNet cho face recognition
- ResNet cho transfer learning
- Attention mechanism trong computer vision
- AdaBoost cho classical ML

### 3. METHODOLOGY (PhÆ°Æ¡ng PhÃ¡p)

#### 3.1 Dataset
```
- Nguá»“n: [MÃ´ táº£ nguá»“n dataset]
- Preprocessing: Aligned faces, resize 224Ã—224
- Augmentation: Horizontal flip, rotation, color jitter
- Split: 70-15-15 (Train-Val-Test)
```

#### 3.2 Model Architectures

**MÃ´ táº£ chi tiáº¿t tá»«ng model:**

**Vanilla CNN:**
```python
Input (224Ã—224Ã—3)
â†’ Conv(3â†’32) â†’ BN â†’ ReLU â†’ MaxPool  # 224â†’112
â†’ Conv(32â†’64) â†’ BN â†’ ReLU â†’ MaxPool  # 112â†’56
â†’ Conv(64â†’128) â†’ BN â†’ ReLU â†’ MaxPool # 56â†’28
â†’ Conv(128â†’256) â†’ BN â†’ ReLU â†’ MaxPool # 28â†’14
â†’ AdaptiveAvgPool(7Ã—7) â†’ Flatten
â†’ FC(12544â†’512) â†’ ReLU â†’ Dropout(0.5)
â†’ FC(512â†’256) â†’ ReLU â†’ Dropout(0.5)
â†’ FC(256â†’294)
```

**ResNet50:**
```python
Pre-trained ResNet50 (ImageNet)
â†’ Replace FC layer: 2048 â†’ 294 classes
â†’ Fine-tune entire network
```

**Attention CNN:**
```python
Features:
  Conv Blocks (3â†’64â†’128â†’256)
Attention:
  Conv(256â†’128â†’1) â†’ Sigmoid â†’ Spatial weights
Classifier:
  GlobalAvgPool â†’ FC(256â†’512â†’294)
```

**AdaBoost:**
```python
Feature Extraction:
  - Pixel values: 16Ã—16 = 256 features
  - Histogram: 16 bins
  - LBP patterns: 100 features
Classifier:
  100 Decision Stumps (max_depth=1)
```

#### 3.3 Training Configuration

```
Optimizer: Adam (lr=0.001)
Loss: CrossEntropyLoss
Batch Size: 32
Max Epochs: 200

Early Stopping:
  - Patience: 15 epochs
  - Min delta: 0.001 (0.1%)

LR Scheduler: ReduceLROnPlateau
  - Factor: 0.5
  - Patience: 7 epochs
```

#### 3.4 Evaluation Metrics

```
- Accuracy: (TP + TN) / Total
- Precision: TP / (TP + FP)
- Recall: TP / (TP + FN)
- F1-Score: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
- Inference Time: Thá»i gian predict trÃªn test set
```

### 4. RESULTS (Káº¿t Quáº£)

**Sá»­ dá»¥ng biá»ƒu Ä‘á»“:**

#### Table 1: Overall Performance
*Dá»¯ liá»‡u tá»« `model_comparison_results.csv`*

| Model | Test Acc | Precision | Recall | F1 | Inference |
|-------|----------|-----------|--------|----|-----------| 
| Vanilla CNN | XX.XX% | XX.XX% | XX.XX% | XX.XX% | X.XXXs |
| ResNet50 | XX.XX% | XX.XX% | XX.XX% | XX.XX% | X.XXXs |
| Attention CNN | XX.XX% | XX.XX% | XX.XX% | XX.XX% | X.XXXs |
| AdaBoost | XX.XX% | XX.XX% | XX.XX% | XX.XX% | X.XXXs |

#### Figure 1: Training Curves
*Tá»« `model_comparison_summary.png`*

MÃ´ táº£:
- ResNet50 converge nhanh nháº¥t (epoch XX)
- Vanilla CNN cÃ³ overfitting tá»« epoch XX
- Attention CNN á»•n Ä‘á»‹nh, learning rate decay hiá»‡u quáº£

#### Figure 2: Individual Training Analysis
*Tá»« `resnet50_training_analysis.png`*

PhÃ¢n tÃ­ch:
- Train-Val gap: Äo lÆ°á»ng overfitting
- Learning rate schedule: Giáº£m dáº§n khi plateau
- Early stopping triggered táº¡i epoch XX

#### Figure 3: Model Comparison
*Tá»« `model_comparison_summary.png`*

So sÃ¡nh:
- ResNet50: Accuracy cao nháº¥t nhÆ°ng inference cháº­m
- Vanilla CNN: Balance tá»‘t
- AdaBoost: Tháº¥p nháº¥t nhÆ°ng explainable

### 5. DISCUSSION (Tháº£o Luáº­n)

#### 5.1 Performance Analysis

**ResNet50 (Best Accuracy):**
- Pre-trained features tá»« ImageNet giÃºp generalize tá»‘t
- Transfer learning hiá»‡u quáº£ cho face recognition
- Trade-off: Model size lá»›n (90MB), inference cháº­m

**Vanilla CNN:**
- ÄÆ¡n giáº£n, dá»… deploy
- CÃ³ hiá»‡n tÆ°á»£ng overfitting tá»« epoch XX
- Early stopping giÃºp trÃ¡nh train quÃ¡ lÃ¢u

**Attention CNN:**
- Spatial attention giÃºp focus vÃ o facial features
- CÃ¢n báº±ng giá»¯a accuracy vÃ  efficiency
- PhÃ¹ há»£p cho production

**AdaBoost:**
- Accuracy tháº¥p do hand-crafted features
- KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c spatial information
- Æ¯u Ä‘iá»ƒm: Interpretable, khÃ´ng cáº§n GPU

#### 5.2 Early Stopping Analysis

*Dá»¯ liá»‡u tá»« `complete_analysis.json`*

```
- Vanilla CNN stopped at epoch XX (patience triggered)
- ResNet50 stopped at epoch XX
- Attention CNN stopped at epoch XX

â†’ Tiáº¿t kiá»‡m XX% thá»i gian so vá»›i train full 200 epochs
â†’ Best val accuracy Ä‘Æ°á»£c save, trÃ¡nh overfitting
```

#### 5.3 Learning Rate Schedule

*Tá»« training curves*

```
All models benefit from ReduceLROnPlateau:
- LR giáº£m khi val accuracy plateau
- Fine-tuning tá»‘t hÆ¡n á»Ÿ late epochs
- Convergence á»•n Ä‘á»‹nh
```

### 6. CONCLUSION (Káº¿t Luáº­n)

#### Recommendations:

**1. Há»‡ thá»‘ng cáº§n accuracy cao:**
â†’ Sá»­ dá»¥ng **ResNet50**
- Accuracy: XX.XX%
- PhÃ¹ há»£p: Server-based system, GPU available

**2. Real-time attendance:**
â†’ Sá»­ dá»¥ng **Vanilla CNN** hoáº·c **Attention CNN**
- Inference < X.XXs
- PhÃ¹ há»£p: Live camera feed, multiple students

**3. Mobile/Edge deployment:**
â†’ Sá»­ dá»¥ng **Vanilla CNN**
- Model size: XX MB
- PhÃ¹ há»£p: Smartphone, Raspberry Pi

**4. Explainability required:**
â†’ Sá»­ dá»¥ng **AdaBoost**
- Feature importance analysis
- PhÃ¹ há»£p: Research, debugging

#### Future Work:
1. Thá»­ nghiá»‡m vá»›i MobileNet, EfficientNet
2. Ãp dá»¥ng Face Verification (Siamese Network)
3. Test trÃªn dataset lá»›n hÆ¡n (>1000 students)
4. Real-time deployment vÃ  performance testing

---

## ğŸ› ï¸ TROUBLESHOOTING

### Lá»—i ThÆ°á»ng Gáº·p

#### 1. Out of Memory (OOM)
```python
# Giáº£m batch size
batch_size = 16  # thay vÃ¬ 32

# Hoáº·c clear cache thÆ°á»ng xuyÃªn
torch.cuda.empty_cache()
```

#### 2. Dataset khÃ´ng tÃ¬m tháº¥y
```python
# Kiá»ƒm tra path
!ls /content/drive/MyDrive/
# Update DATASET_DIR_DRIVE náº¿u cáº§n
```

#### 3. Training quÃ¡ cháº­m
```python
# Äáº£m báº£o Ä‘ang dÃ¹ng GPU
print(torch.cuda.is_available())  # Should be True
```

#### 4. Early Stopping trigger quÃ¡ sá»›m
```python
# TÄƒng patience
patience = 20  # thay vÃ¬ 15

# Hoáº·c giáº£m min_delta
min_delta = 0.0001  # thay vÃ¬ 0.001
```

---

## ğŸ“š REFERENCES

### Papers:
1. He et al. (2016) - Deep Residual Learning for Image Recognition
2. Vaswani et al. (2017) - Attention Is All You Need
3. Freund & Schapire (1997) - A Decision-Theoretic Generalization of On-Line Learning

### Datasets:
- ImageNet (pre-training)
- Your custom student face dataset

### Frameworks:
- PyTorch 2.8.0
- OpenCV 4.12.0
- scikit-learn

---

## ğŸ’¡ TIPS CHO NGHIÃŠN Cá»¨U KHOA Há»ŒC

### 1. Reproducibility
```python
# Set seed Ä‘á»ƒ reproduce káº¿t quáº£
torch.manual_seed(42)
np.random.seed(42)
```

### 2. Ablation Study
- Thá»­ nghiá»‡m vá»›i/khÃ´ng cÃ³ data augmentation
- So sÃ¡nh different patience values
- Test vá»›i different LR schedules

### 3. Statistical Significance
- Cháº¡y multiple runs (3-5 láº§n)
- BÃ¡o cÃ¡o mean Â± std
- Confidence intervals

### 4. Visualization
- Use high-DPI images (300 dpi)
- Clear labels and legends
- Consistent color schemes

---

## ğŸ“ CONTACT & SUPPORT

Náº¿u cÃ³ váº¥n Ä‘á»:
1. Kiá»ƒm tra [Troubleshooting](#troubleshooting)
2. Review error messages
3. Check Google Colab resources (RAM/GPU usage)

**Good luck with your research! ğŸ“**
